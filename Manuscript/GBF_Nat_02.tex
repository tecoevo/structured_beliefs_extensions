\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage{times}
\usepackage[titletoc]{appendix}
\usepackage{graphicx}
\usepackage[running]{lineno}
\usepackage{multirow}
\usepackage[english]{babel}
\usepackage{typearea} 
\usepackage{amssymb}
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{enumerate}
\usepackage{mathtools}
\usepackage{graphicx}
\usepackage{wrapfig}
\usepackage{lscape}
\usepackage{rotating}
\usepackage[numbers]{natbib}
\usepackage[colorinlistoftodos]{todonotes}
\newcommand{\Fig}[1]{Figure~\ref{fig:#1}}

\renewcommand{\baselinestretch}{1.5}
\newcommand{\bbar}[1]{\overline{#1}}

\newcommand\scalemath[2]{\scalebox{#1}{\mbox{\ensuremath{\displaystyle #2}}}}
\renewcommand{\familydefault}{\sfdefault}

\usepackage[font={small},labelfont={bf},justification=justified,margin=0.5cm]{caption}

\renewcommand{\thesection}{}
\renewcommand{\thesubsection}{\arabic{section}.\arabic{subsection}}

\usepackage{color}
         \definecolor{darkred}{rgb}{0.9,0,0}
%         \definecolor{darkgreen}{rgb}{0,0.5,0}
         \definecolor{darkblue}{rgb}{0,0,0.75}
%         \definecolor{magenta}{rgb}{0,0,0.75}
\newcommand{\hhone}{(H,H,1)}
\newcommand{\hhtwo}{(H,H,2)}
\newcommand{\hsone}{(H,S,1)}
\newcommand{\hstwo}{(H,S,2)}
\newcommand{\shone}{(S,H,1)}
\newcommand{\shtwo}{(S,H,2)}
\newcommand{\ssone}{(S,S,1)}
\newcommand{\sstwo}{(S,S,2)}

\newcommand{\hhstar}{(H,H,$\star$)}


\usepackage{hyperref}
\definecolor{darkgreen}{rgb}{0.1,0.6,0.3}
\definecolor{darkred}{rgb}{0.6,0.3,0.1}
\hypersetup{
    colorlinks=true,       % false: boxed links; true: colored links
    linkcolor=blue,          % color of internal links (change box color with linkbordercolor)
    citecolor=darkgreen,        % color of links to bibliography
    filecolor=magenta,      % color of file links
    urlcolor=black%color of external links
}


% remove this before we submit...
\definecolor{greenie}{rgb}{0.1,0.62,0.0}
\definecolor{orange}{rgb}{0.9,0.3,0.0}
\definecolor{deepblue}{rgb}{0.0,0.0,0.7}
\newcommand{\cha}[1]{\textcolor{darkgreen}{(#1)}} 


\title{\vspace*{-22mm}\bf Title}
%\author{Chaitanya S. Gokhale$^{1}$, Joseph Bulbulia$^{2,3}$, Marcus Frean$^{4}$\\
%\normalsize $^1$Research Group for Theoretical Models of Eco-evolutionary Dynamics\\
%\normalsize Department of Evolutionary Theory, \\
%\normalsize Max-Planck Institute for Evolutionary Biology, 24306 Pl\"{o}n, Germany, \\
%\normalsize $^2$School of Humanities, Faculty of Arts, University of Auckland, New Zealand \\
%\normalsize $^3$Max Planck Institute for the Science of Human History, Jena, Germany \\
%\normalsize $^4$School of Engineering and Computer Science, \\
%\normalsize Victoria University of Wellington, New Zealand
%}


\date{}

\begin{document}



\linenumbers
\maketitle

\begin{abstract}
% Suggest we set this up differently:
Abstract stuff
\end{abstract}


\noindent
Keywords: 


\tableofcontents

\section{Introduction}




%\textbf{Collective cooperation and resource dynamics}.
%

\section{Deterministic dynamics}
\subsection{Replicator Dynamics}

\subsubsection{Two player games with two strategies}

Replicator dynamics is one of the possible frameworks that can explain evolutionary dynamics. 
Replicator dynamics determines how the frequency of different strategies in a population changes over time. 
We can write the equation used to determine replicator dynamics mathematically. Let's take the frequency of $A$ and $B$ strategies are $x_A$ and $x_B$ and the fitness of each strategy is $f_A$ and $f_B$ and the average fitness of the population is $\bar{f}$. 
It is a two-player two-strategy game so we can say, $ x_A+x_B=1 $, so we can write that $x_B=1-x_A$ and $x_A=1-x_B$. Let's try to write a payoff matrix,

\begin{linenomath}
\begin{equation}
\begin{pmatrix}
& A & B \\
  A & a_1 & a_0 \\
  B & b_1 & b_0
\end{pmatrix}
\end{equation}
\end{linenomath}

Now based on the payoffs we can write the average fitness of each strategy.
\begin{linenomath}
\begin{align}
f_A &=x_A\cdot a_1 + (1-x_A)\cdot a_0 \nonumber\\
f_B &=x_B\cdot b_1 + (1-x_B)\cdot b_0 \nonumber
\end{align} 
\end{linenomath}
Now to keep the average fitness of the population constant, we can write an equation.
\begin{align}
\bar{f}= (x_Af_A+x_Bf_B)\label{eq:1}
\end{align}
Now, we can substitute this $x_B$ value into the equation \ref{eq:1}. After substitution, we will get the undermentioned equation.
\begin{align}
\bar{f}={x_Af_A+ (1-x_A)f_B}\label{eq:2}
\end{align}
We can write two differential equations for replicator dynamics using the above information.
\begin{align}
\frac{dx_A}{dt} = x_A(f_A - \bar{f}) \nonumber \\
\frac{dx_B}{dt} = x_B(f_B - \bar{f}) \label{eq:3}
\end{align}
Now let's substitute the equation \eqref{eq:2} into the equation \eqref{eq:3}.
\begin{align}
\frac{dx}{dt} &=x_A[f_A-(x_Af_A+(1-x_A)f_B)] \nonumber\\
          &=x_A[f_A-x_Af_A-f_B+x_af_B] \nonumber\\
          &=x_A[(1-x_A)f_A-(1-x_A)f_B] \nonumber\\
          &=x_A(1-x_A)(f_A-f_B) \label{eq:4}
\end{align}
This is for a two-strategy game. If we have $n$ strategies,where $i=1,2,3.....(n-1)$.We can write the undermentioned equation.
\[\frac{dx_i}{dt}=x_i[f_i(x)-\bar{f}]\]
What does this equation tell us? 
We can understand that the rate of change with time of the frequency of a certain type  depends on the fitness, average fitness of the population, and frequency. From this understanding, we can say that if $f_i(x)-\bar{f}>0$ then the frequency of this type will increase over time, and if $f_i(x)-\bar{f}<0$, the frequency of the type will decrease over time.
Now, We can write the replicator dynamics \eqref{eq:4}.
\[\frac{dx}{dt}=x_A(1-x_A)(f_A-f_B)\]
If we make the change of strategy $A$ constant over time, which means $\frac{dx}{dt}=0$ then we can write the replicator dynamics equation as:
\[x_A(1-x_A)(f_A-f_B)=0\]
Now, if we try to find certain conditions under which $\frac{dx}{dt}$ will be $0$.
We will have three certain conditions, $x=0$, $x=1$ and $f_A=f_B$.
In graphical representation, for the condition $f_A=f_B$, it will make a straight line between the $0$ and $1$. If the condition is $f_A>f_B$ then the curve will be over the straight line and if $f_A<f_B$ then the curve will be under the straight line\cite{Bishop1976} For a visual representation of this graph, we can plot this equation for different values of $f_A$ and $f_B$ using Python.\\
We can calculate the particular frequency where the strategy $A$ becomes abundant from rare or rare from abundant. We can calculate this using the $f_A=f_B$ equation.\\
Let's take this frequency as $x^*$.
As we know, $f_A=f_B$
So we can write,
\begin{align}
&xa_1+(1-x)a_0 =xb_1+(1-x)b_0 \nonumber\\
&x(a_1-a_0)+a_0=x(b_1-b_0)+b_0 \nonumber\\
&x(a_1-a_0-b_1+b_0)=b_0-a_0 \nonumber\\
&x=\frac{b_0-a_0}{a_1-a_0-b_1+b_0} \nonumber
\end{align}
We can write the $x$ as $x^*$
\begin{align}
x^*=\frac{b_0-a_0}{a_1-a_0-b_1+b_0} \label{eq:5}
\end{align}
We get different conditions from this equation.\\
(1) Dominance: It happens when any one of the two strategies will be dominant over another, means, for example, if $f_A>f_B$, that strategy $A$ will be dominant over strategy $B$. It will be possible if the $a_1>b_1$ and $a_0>b_0$ where $a_1,a_0,b_1,b_0$ are the payoffs of a payoff matrix of a two-player two-strategy game.\\
(2) Co-existence: It happens when one of the two strategies is rare and has an advantage for that. For example, if strategy $A$ is rare, then $f_A>f_B$. if $a$ becomes abundant, it will lose its advantage, so the inequality will be  $f_A<f_B$, and while becoming abundant strategy from rare strategy, there will be an internal equilibrium point and the equation will $f_A=f_B$. In this scenario, the player should play the rare strategy.It will be possible if the $a_1<b_1$ and $a_0>b_0$ where $a_1,a_0,b_1,b_0$ are the payoffs of a payoff matrix of a two-player two-strategy game.\\
(3) Bi-stability: A condition where all $A$ and $B$ will be stable. It means that a strategy will get an advantage if it is abundant. For example, if strategy $A$ is abundant, then the inequality will be $f_A>f_B$, and if it becomes rare, then the inequality will be $f_A<f_B$, and there will be a internal equilibria when $f_A=f_B$. For this condition, the player should play the strategy its opponent is playing. It will be possible if the $a_1>b_1$ and $a_0<b_0$ where $a_1,a_0,b_1,b_0$ are the payoffs of a payoff matrix of a two-player two strategy game.\\
(4) Neutrality: Now, we have one condition in which both strategies will have the same impact. It does not depend on the change in the strategy. The equation for this strategy is $f_A=f_B$. It will be possible if $a_1=b_1$ and $a_0=b_0$ where $a_1,a_0,b_1,b_0$ are the payoffs of a payoff matrix of a two-player two-strategy  game.\cite{Gokhale2011}.\\
Now, based on the above explained process of replicator dynamics for two players with two strategies, we will explore some games and find their internal equilibrium point.\\
\textbf{Prisoner's dilemma}
\newline
The prisoner's dilemma is a fundamental game in game theory, which represents that two rational individuals might not cooperate, even if it benefits them mutually.\\
The game goes on as two prisoners ($A$ player and $B$ player) are arrested by a policeman and offered some separate deals.\\
There will be mainly three conditions:
\begin{enumerate}
\item If both prisoners cooperate, they will get an equal and moderate amount of sentence.
\item If one prisoner defects, the defector will get no sentence, but the cooperator gets a longer sentence.
\item If both players defect, both will get a lower and equal sentence.
\end{enumerate}
Let's try to write the payoff matrix.
\[
\begin{array}{c|cc}
   & \text{Cooperate (C)} & \text{Defect (D)} \\
  \hline
  \text{Cooperate (C)} & R = 3 & S = 0 \\
  \text{Defect (D)} & T = 5 & P = 1 \\
\end{array}
\]
The general and standard condition for prisoner' dilemma is $a_1<b_1$ and $a_0<b_0$. As mentioned in the replicator dynamics section, there are three conditions where the value of $dx/dt$ will be $0$. The three conditions are $x=0$, it means only defectors, and $x=1$, which means only cooperators. The internal equilibrium will fulfil the condition of $f_C=f_D$. Let's find the equilibrium point by using the equation \eqref{eq:5} and putting the payoff values into the equation.
\begin{align}
x^*&=\frac{1-0}{3-0-5 +1} \nonumber\\
x^*&= -1 \nonumber
\end{align}
Since, $x\in{0,1}$ so there can not exist any internal equilibrium valued $-1$. This states that the entire system will have transition to full defection $(x=0)$ over time.
We can plot the graph using Python for the Prisoner's dilemma dynamics.\\
\textbf{Chicken Game}
\newline
In this game, two players( player $A$ and player $B$)are driving towards each other in a single pathway. There are two options for the players:
\begin{enumerate}
\item Swerve(C)- Avoided collision but appeared weak.
\item Stay (D)- Stay driving toward each other, hoping the opponent will swerve.
\end{enumerate}
We can write three conditions based on this:
\begin{enumerate}
\item If both swerves, they will not face collision, but there will be a small loss.
\item If one swerves and one stays, the one who stays will have a win, and one who swerves will face loss.
\item If both stay, they'll have a huge loss.
\end{enumerate}
We can write the payoff matrix with actual payoffs, which follow the standard condition, $a_1<b_1$ and $a_0>b_0$.
\[
\begin{array}{c|cc}
   & \text{Swerve} & \text{Stay} \\
  \hline
  \text{Swerve} & -c = -3 & b = 4 \\
  \text{Stay} & 0 = 0 & \frac{b}{2} = 2 \\
\end{array}
\]
As we know, there are three conditions where the value of $dx/dt$ will be $0$. The three conditions are $x=0$, it means only defectors, and $x=1$, which means only cooperators. The internal equilibrium will fulfil the condition of $f_C=f_D$.Let's find the equilibrium point by using the equation \eqref{eq:5} and putting the payoff values into the equation.
\begin{align}
x^*&= \frac{2-4}{-3-4-0+2} \nonumber\\
x^*&= \frac{2}{5} \nonumber
\end{align}
This implies that, over time $2/5$ of the population will swerve and $3/5$ of the population will stay.It implies the condition of co-existence. Let's try to plot it.\\
\textbf{Stag Hunt Game}
\newline
Stag hunt game is a classical example of game theory for understanding social dilemma and the interplay between risk and trust.
In this game, two players are hunting in a forest. They have two choices,Cooperate(C) with each other and hunt stag or Independently hunt hare(D).\\
We can write three conditions based on this:
\begin{enumerate}
\item If they both cooperate and hunt stag, they will get the highest payoff.
\item If One goes for the stag hunt and the other one hunts hare, the one who hunts stag will get nothing and the one who hunts hare will get a lower payoff.
\item If they both defect and independently hunt hare, they will get a lower payoff.
\end{enumerate}
We can write the payoff matrix using actual values, which follow the conditions of $a_1>b_1$ and $a_0<b_0$.
\[
\begin{array}{c|cc}
   & \text{Cooperate (C)} & \text{Defect (D)} \\
  \hline
  \text{Cooperate (C)} & S = 4 & S = 0 \\
  \text{Defect (D)} & H = 3 & H = 3 \\
\end{array}
\]
As we know, there are three conditions where the value of $dx/dt$ will be $0$. These three conditions are $x=0$, it means only defectors, and $x=1$, which means only cooperators. The internal equilibrium will fulfil the condition of $f_C=f_D$.Let's find the equilibrium point by using the equation \eqref{eq:5} and putting the payoff values into the equation.\\
\begin{align}
x^* &=\frac{3-0}{4-0-3+3} \nonumber\\
x^* &= \frac{3}{4} \nonumber
\end{align}
Over time, $3/4$ of the population will hunt stag and the $1/4$ of the population will hunt hare.\\
\subsubsection{Two player games with multiple strategies}
In the previous subsection, we analysed two player games with two strategies, now we are going to analyse two player games with multiple strategies.For better understanding of this particular problem, let's take a biological example, strains of \textit{Escherichia coli} are competing for resources available on the media. $K$ strain is the killer strain which produces toxin that will out-compete strain $S$. So, having toxin or not are the two strategies, we can write this using two strategy payoff matrix but there can be another possibility, where strain $R$ is resistant to the toxin but pay the cost for resistance. SO, the scenario now changed completely; now the payoff matrix will be $3 \times 3$. This study was carried out by\cite{Kerr2002}\cite{Czaran2002}.
Now, in a population there will be multiple strategies. So, we have to write the replicator dynamics in $(n-1)$ dimensional simplex.For that we need $n\times n$ payoff matrix.
\[
\begin{array}{c@{}c}
   & \begin{array}{cccc} 1 & 2 & \dots & n \end{array} \\ 
   \begin{array}{c} 
       1 \\ 
       2 \\ 
       \vdots \\ 
       n 
   \end{array} 
   & 
   \begin{pmatrix}
       a_{1,1} & a_{1,2} & \dots & a_{1,n} \\
       a_{2,1} & a_{2,2} & \dots & a_{2,n} \\
       \vdots & \vdots & \ddots & \vdots \\
       a_{n,1} & a_{n,2} & \dots & a_{n,n}
   \end{pmatrix}
\end{array}
\]
This is a two player game, here $a_{1,2}$ means player $A$ playing strategy $1$ against the strategy $2$ of player $B$ so we can write the equation using replicator dyanmics.
\[dx_i/dt=x_i[f_i(x)-\bar{f}]\]
We can derive the average fitness of a strategy $i$ from this equation.
\[f_i(x)=a_{i,1}x_1+a_{i,2}x_2+.....+a_{i,n}x_n\]
We can write this equation as:
\[f_i(x)=\sum_{j=1}^{n}a_{i,j}x_j\]
and the average fitness of a population is denoted as:
\[\bar{f}=x_1f_1+x_2f_2+.....+x_nf_n= \sum_{i=1}^{n}x_if_i \]
\textbf{Rock-Paper-Scissors Game}
\newline
Rock paper scissors game is a game in game theory where, there are $n=3$ strategies for each player. In this game, there are mainly three conditions:
\begin{enumerate}
\item If rock, paper and scissors meet respectively with rock, paper and scissors, the payoff will be zero.
\item If rock meets with scissors and paper with rock and scissors with paper, they will get the highest payoff.
\item If the rock meets with paper and paper with scissors and scissors with rock, they will get the lowest payoff.
\end{enumerate}
Let's try to write the payoff matrix.
\[
A =
\begin{pmatrix}
  & R & S & P \\
R & 0 & 1 & -1 \\
S & -1 & 0 & 1 \\
P & 1 & -1 & 0
\end{pmatrix}
\]
Let's write the average fitness for each strategy,\\
For Rock,
\begin{align}
f_R &= (0)x_R + (1)x_S + (-1)x_P \nonumber\\
f_R &= x_S - x_P \nonumber
\end{align}
For Scissors,
\begin{align}
f_S &= (-1)x_R + (0)x_S + (1)x_P \nonumber\\
f_S &= x_P - x_R \nonumber
\end{align}
For Paper,
\begin{align}
f_P &= (1)x_R + (-1)x_S + (0)x_P \nonumber\\
f_P &= x_R - x_S \nonumber
\end{align}
$x_R,x_S,x_P$ are the frequencies of choosing rock, scissors and paper respectively, and we can write,
\begin{align}
x_R+x_S+x_P=1 \label{eq:6}
\end{align}
Now the mathematical condition for finding the internal equilibrium is $f_R=f_S=f_P$.
\begin{align}
f_R &=f_S \nonumber\\
x_S-x_P &=x_P-x_R \nonumber\\
2x_P &=x_S+x_R \label{eq:7}
\end{align}
\begin{align}
f_S &=f_P \nonumber\\
x_P-x_R &=x_R-x_S \nonumber\\
2x_R &=x_P+x_S \label{eq:8}
\end{align}
\begin{align}
f_R&=f_P \nonumber\\
x_S-x_P&=x_R-x_S \nonumber\\
2x_S&=x_R+x_P \label{eq:9}
\end{align}
Now if we replace the value of \eqref{eq:7} into the equation \eqref{eq:6} we will get,
\begin{align}
x_R+x_S+x_P&=1\nonumber\\
2x_P+x_P&=1\nonumber\\
x_P&=\frac{1}{3}\nonumber
\end{align}
If we replace the value of \eqref{eq:8} and \eqref{eq:9} into the equation \eqref{eq:6} in the same manner, we will get $x_P=x_R=x_S=\frac{1}{3}$. In this game no player will gain an advantage by changing their strategies. 
\section{Stochastic Process and Finite Population}
\subsection{Two players with two strategies}
In the previous subsection, we used an infinite population for the deterministic approach \cite{Hofbauer2003}. Now, we will proceed with a finite population. There are mainly two reasons to use a finite population: first, it is realistic, and second, it is a natural way to introduce randomness into the replicator dynamics\cite{Altrock2010}.
Now, we can consider the finite population of a specific game as $N$.Let's assume there are two strategies $a$ and $b$. Frequencies for $a$ and $b$ are $i$ and $(N-i)$. We can write the payoff matrix according to this specification,
\[
\begin{array}{c|cc}
    & a & b \\
    \hline
  a & (a_1) & (a_0) \\
  b & (b_1) & (b_0)
\end{array}
\]
Now we can denote the average payoff of $a$ and $b$ strategies as $\pi_a$ and $\pi_b$.
\[\pi_a=\frac{i-1}{N-1}a_1 + \frac{N-i}{N-1}a_0\]
\[\pi_b=\frac {i}{N-1}b_1 + \frac{N-i-1}{N-1}b_0\]
Now, a question can arise, why are we using $i-1$ instead of $i$? We have to understand that instead of an infinitely large population, we are using a real finite population and for that, we have to remove the particular individual who is observing or analysing this situation. So we use $i-1$.
In the previous work, we used fitness directly related to payoff. But in the actual population, we introduce a tunable parameter similar to the fitness which controls the game.
Nowak et al.~\cite{Nowak2004} introduced this tunable parameter as selection intensity. Because for some situations or equations, we can know the particular relation between the fitness and payoff but for most of cases, we don't know the particular relation; we can just create a hypothesis.
\[f_i=1-w+w\pi_i\]
where $w$ selection intensity and $\pi_i$ is the payoff. The value of $w$ is bound by  $0$ and $1$. If the value is $0$, then $f_i=1$. We can deduce from this equation that for every value of $i$, we will face neutrality, and if the value is $1$, we will have $f_i=\pi_i$. Now, it suggests that the game payoff controls the fitness.
Now, we can move to the part of the evolutionary dynamics where, for the finite population, there's randomness involved in the population. So, we will go for the stochastic processes.
For these stochastic processes, we will focus on the Moran process. It consists of two events: birth and death. For the birth process, one subject is chosen randomly, and it produces its identical copy, and for the death process, again, one random subject is chosen from the population and eliminated. It means by introducing randomness with the birth-death process, now this theory can change the population with each time step, and for $N$ steps it will control a generation \cite{Moran1962}
There are three mathematical equations that we can derive from this theory: (1) The number of $a$ individuals increases by 1; (2) the number of $a$ individuals decreases by 1; (3) the number of $a$ individuals remains neutral.\\
For the (1) scenario, we can write:
\[T_i^+=\frac{if_a}{if_a+(N-i)f_b}\frac{N-i}{N}\]
For the (2) scenario, we can write:
\[T_i^-=\frac{(N-i)f_a}{if_a+(N-i)f_b}\frac{i}{N}\]
For the (3) scenario, we can write:
\[1-T_i^+-T_i^-\]
Now, what can we deduce from these equations?\\
From the (1) equation, we can say that $a$ numbered individuals can increase only when an $a$ individual is chosen for birth and a $b$ individual is chosen for death.\\
From the (2) equation, we can say that the number of $a$ decreases cause an $a$ individual is chosen for death and a $b$ individual is chosen for birth.\\
From the (3) equation, we can deduce that no one is chosen for the birth or death process, so there is neutrality.\\
Now, let us jump to the fixation probability.\\
In genetics, we often ask a question related to the invasion of a gene: how can the gene invade another gene, and how does it affect the other gene's population?
After understanding the transition probability and Moran processes, we can now form a question based on the previously mentioned topic. In a population of $j$ numbered $a$ individuals and $(N-j)$ numbered $b$ individuals, what is the probability that the whole population will consist of $a$ individuals?
This is known as the fixation probability of $j$ numbered $a$ individuals.We can denote this fixation probability as $\rho(j)$.
Since fixation is an absorbing state, if the entire population once becomes $a$, it can not be reverted. We can try to write a probability balance equation.
\[\rho(j)=T_i^+\rho_a(j+1)+(1-T_i^+-T_i^-)\rho_a(j)+T_i^-\rho_a(j-1)\]
This is a discrete stochastic process that we can derive using the absorbing phenomenon of Markov chain processes.
Let's solve this equation.
\[\rho_a(j)-\rho_a(j-1)=\frac{T_i^-}{T_i^+}(\rho_a(j+1)-\rho_a(j))\]
\[T_i^++(\rho_a(j)-\rho_a(j-1)=T_i^-(\rho_a(j+1)-\rho_a(j)\]
\[T_i^+\rho_a(j)-T_i^+\rho_a(j-1)=T_i^-\rho_a(j+1)-T_i^-\rho_a(j)\]
\[\rho_a(j+1)=\frac{\rho_a(j)(T_i^+ + T_i^-)-T_i^+\rho_a(j+1)}{T_i^-}\]
 Now, let's write the equation.\\
 $Ratio_j=R_j=\frac{T_i^-}{T_i^+}= \frac{(N-j)f_b}{jf_a}$
 Let's substitute the value of $R_j$
 \[\rho_a(j+1)={\rho_a(j)(1+R_j)-R_j\rho_a(j-1)}\]
 Let's solve this equation by putting some real values,\\
 We get this underwritten equation by putting the value of $j=1$,
 \[\rho_a(2)= \rho_a(1)(1+R_1)-R_1\rho_a(0)\]
 Let's put $j=2$.
 \[\rho_a(3)=\rho_a(2)(1+R_2)-R_2\rho_a(1)\]
 Let's substitute the value of $\rho_a(2)$
 \[\rho_a(3)=\rho_a(1)(1+R_1)(1+R_2)-\rho_a(1)\]
 \[\rho_a(3)=\rho_a(1)((1+R_1)(1+R_2)-1)\]
 Now we can write a general equation based on this.
 \[\rho_a(j)=\left[1+\sum_{m=1}^{j-1}\prod_{i=1}{m}R_i \right] \rho_a(1)\]
 Since we know that $j=N$, and fixation is guaranteed means $\rho_a(N)=1$
 \[1=\left[1+\sum_{m=1}^{N-1}\prod_{i=1}^{m} R_i\right]\rho_a(1)\]
 \[\rho_a(1)=\frac{1}{1+\sum_{m=1}^{N-1}\prod_{i=1}^{m}R_i}\]
 We can use the above equation when proceeding with just a $1$ player population.
 So, we can write the final fixation probability equation as,
 \[\rho(j)=\frac{1+\sum_{m=1}^{j-1}\prod_{i=1}^{m}R_i}{1+\sum_{m=1}^{N-1}\prod_{i=1}^{m}R_i}\]
 If we consider a neutral drift, where $f_a=f_b$, then we can write the equation as $\rho_a={j}/{N}$.
 If we observe the neutral drift with a single individual, we can write $\rho_a=1/N$\cite{Traulsen2006}. We can calculate the fixation probability for strategy $b$ as $\rho_b$. $1$ $b$ individual reaches fixation is equal to the $N-1$ $a$ individuals fails to reach fixation.
\[\rho_b=1-\rho_a(N-1)\]
\[=1-\frac{1 + \sum_{m=1}^{N-2} \prod_{i=1}^{m} R_i}{1 + \sum_{m=1}^{N-1} \prod_{i=1}^{m} R_i}\]
\[=\frac{1}{1+\sum_{m=1}^{N-1}\prod_{i=1}^{m}R_i}(\prod_{i=1}^{N-1}R_i)\]
\[=\rho_a(\prod_{i=1}^{N-1}R_i)\]
Now, we can write about the one-third rule.\\
The selection of one particular strategy means the fixation probability is greater than neutral.
 \[\rho_a>1/N\]
 But if you want to calculate for the weak selection, the fitness will be,
 \[f_a=1+w\pi_a\]
 \[f_b=1+w\pi_b\]
 We can write the ratio of transition probabilities using the above-mentioned equations,
 \[R_i=\frac{T_i^-}{T_i^+}= \frac{(N-j)f_b}{jf_a}\approx\frac{N-j}{j}(1+w(\pi_b-\pi_a) \]
 For small \( w \), we take a logarithmic expansion and approximate,
\[\prod_{j=1}^{m} R_i \approx \prod_{j=1}^{m} \frac{N-j}{j} \left( 1 + w (\pi_B - \pi_A) \right)\]
\[\prod_{j=1}^{m} \frac{N-j}{j} = \frac{(N-1)!}{m!(N-m-1)!} \approx N^m.\]
The weak selection term contributes an additional summation,
\[\sum_{m=1}^{N-1} \sum_{j=1}^{m} (\pi_A - \pi_B).\]
Now, we know that,
\[\sum_{m=1}^{N-1} \prod_{j=1}^{m} R_i \approx N^m - 1 + w \sum_{m=1}^{N-1} \sum_{j=1}^{m} (\pi_B - \pi_A)\]
Now, we can write,
\[\rho_A(1) \approx \frac{1}{1 + \sum_{m=1}^{N-1} \prod_{j=1}^{m} R_i}\]
Finally, we can summarise the whole equation as,
\[\rho_A(1) \approx \frac{1}{N} + \frac{w}{N^m} \sum_{m=1}^{N-1} \sum_{j=1}^{m} (\pi_A - \pi_B)\]
\section{Discussion}
\textbf{Code availability}.
Appropriate computer code describing the model is available at 
\texttt{ REDACTED for review}.% {\url{https://github.com/tecoevo/beliefs}}.
\section{Acknowledgements}
\texttt{ REDACTED for review}.% {\url{https://github.com/tecoevo/beliefs}}.
\bibliographystyle{naturemag}
\bibliography{references.bib}
\renewcommand{\theequation}{SI.\arabic{equation}}
\setcounter{equation}{0}
\renewcommand{\thefigure}{SI.\arabic{figure}}
\setcounter{figure}{0}
\section{Supplementary material}
\subsection{Analysis of the simple system}
\end{document}
