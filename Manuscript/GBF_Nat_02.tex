\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage{times}
\usepackage[titletoc]{appendix}
\usepackage{graphicx}
\usepackage{lineno}
\usepackage{multirow}
\usepackage[english]{babel}
\usepackage{typearea} 
\usepackage{amssymb}
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{enumerate}
\usepackage{mathtools}
\usepackage{graphicx}
\usepackage{wrapfig}
\usepackage{lscape}
\usepackage{rotating}
\usepackage[numbers]{natbib}
\usepackage[colorinlistoftodos]{todonotes}
\usepackage{float}
\newcommand{\Fig}[1]{Figure~\ref{fig:#1}}

\renewcommand{\baselinestretch}{1.5}
\newcommand{\bbar}[1]{\overline{#1}}

\newcommand\scalemath[2]{\scalebox{#1}{\mbox{\ensuremath{\displaystyle #2}}}}
\renewcommand{\familydefault}{\sfdefault}

\usepackage[font={small},labelfont={bf},justification=justified,margin=0.5cm]{caption}

\renewcommand{\thesection}{}
\renewcommand{\thesubsection}{\arabic{section}.\arabic{subsection}}

\usepackage{color}
         \definecolor{darkred}{rgb}{0.9,0,0}
%         \definecolor{darkgreen}{rgb}{0,0.5,0}
         \definecolor{darkblue}{rgb}{0,0,0.75}
%         \definecolor{magenta}{rgb}{0,0,0.75}
\newcommand{\hhone}{(H,H,1)}
\newcommand{\hhtwo}{(H,H,2)}
\newcommand{\hsone}{(H,S,1)}
\newcommand{\hstwo}{(H,S,2)}
\newcommand{\shone}{(S,H,1)}
\newcommand{\shtwo}{(S,H,2)}
\newcommand{\ssone}{(S,S,1)}
\newcommand{\sstwo}{(S,S,2)}

\newcommand{\hhstar}{(H,H,$\star$)}


\usepackage{hyperref}
\definecolor{darkgreen}{rgb}{0.1,0.6,0.3}
\definecolor{darkred}{rgb}{0.6,0.3,0.1}
\hypersetup{
    colorlinks=true,       % false: boxed links; true: colored links
    linkcolor=blue,          % color of internal links (change box color with linkbordercolor)
    citecolor=darkgreen,        % color of links to bibliography
    filecolor=magenta,      % color of file links
    urlcolor= black           % color of external links
}


% remove this before we submit...
\definecolor{greenie}{rgb}{0.1,0.62,0.0}
\definecolor{orange}{rgb}{0.9,0.3,0.0}
\definecolor{deepblue}{rgb}{0.0,0.0,0.7}
\newcommand{\cha}[1]{\textcolor{darkgreen}{(#1)}}


\title{\vspace*{-22mm}\bf Title}
%\author{Chaitanya S. Gokhale$^{1}$, Joseph Bulbulia$^{2,3}$, Marcus Frean$^{4}$\\
%\normalsize $^1$Research Group for Theoretical Models of Eco-evolutionary Dynamics\\
%\normalsize Department of Evolutionary Theory, \\
%\normalsize Max-Planck Institute for Evolutionary Biology, 24306 Pl\"{o}n, Germany, \\
%\normalsize $^2$School of Humanities, Faculty of Arts, University of Auckland, New Zealand \\
%\normalsize $^3$Max Planck Institute for the Science of Human History, Jena, Germany \\
%\normalsize $^4$School of Engineering and Computer Science, \\
%\normalsize Victoria University of Wellington, New Zealand
%}


\date{}

\begin{document}



\linenumbers
\maketitle




\noindent
Keywords: 


\tableofcontents
\section{Abstract}
\section{Introduction}
\section{Review of Literature}
\section{Methodology}
\subsection{Replicator Dynamics}

\subsubsection{Two-player games with two strategies}

Replicator dynamics is one of the possible frameworks that can explain evolutionary dynamics. Replicator dynamics determines how the frequency of different strategies in a population changes over time. We can write the equation used to assess replicator dynamics mathematically. Let's take the frequency of $A$ and $B$ strategies are $x_A$ and $x_B$ and the fitness of each strategy is $f_A$ and $f_B$ and the average fitness of the population is $\bar{f}$. It is a two-player two-strategy game, so we can say $ x_A+x_B=1 $, so we can write that $x_B=1-x_A$ and $x_A=1-x_B$. Let's try to write a payoff matrix,\\
\[
\begin{pmatrix}
& A & B \\
  A & a_1 & a_0 \\
  B & b_1 & b_0
\end{pmatrix}
\]
Now, based on the payoffs, we can write the average fitness of each strategy.
\begin{align}
f_A &=x_A\cdot a_1 + (1-x_A)\cdot a_0 \nonumber\\
f_B &=x_B\cdot b_1 + (1-x_B)\cdot b_0 \nonumber
\end{align} 
Now, to keep the average fitness of the population constant, we can write an equation.
\begin{align}
\bar{f}= (x_Af_A+x_Bf_B)\label{eq:1}
\end{align}
Now, we can substitute this $x_B$ value into the equation \eqref{eq:1}. After substitution, we will get the following equation.
\begin{align}
\bar{f}={x_Af_A+ (1-x_A)f_B}\label{eq:2}
\end{align}
We can write two differential equations for replicator dynamics using the above information.
\begin{align}
\frac{dx_A}{dt} = x_A(f_A - \bar{f}) \nonumber \\
\frac{dx_B}{dt} = x_B(f_B - \bar{f}) \label{eq:3}
\end{align}
Now let's substitute the equation \eqref{eq:2} into the equation \eqref{eq:3}.
\begin{align}
\frac{dx}{dt} &=x_A[f_A-(x_Af_A+(1-x_A)f_B)] \nonumber\\
          &=x_A[f_A-x_Af_A-f_B+x_af_B] \nonumber\\
          &=x_A[(1-x_A)f_A-(1-x_A)f_B] \nonumber\\
          &=x_A(1-x_A)(f_A-f_B) \label{eq:4}
\end{align}
This is for a two-strategy game. If we have $n$ strategies,where $i=1,2,3.....(n-1)$.We can write the following equation.
\[\frac{dx_i}{dt}=x_i[f_i(x)-\bar{f}]\]
What does this equation tell us? 
We can understand that the rate of change with time of the frequency of a certain type depends on the fitness, average fitness of the population, and frequency. From this understanding, we can say that if $f_i(x)-\bar{f}>0$, then the frequency of this type will increase over time, and if $f_i(x)-\bar{f}<0$, the frequency of the type will decrease over time.
Now, we can write the replicator dynamics \eqref{eq:4}.
\[\frac{dx}{dt}=x_A(1-x_A)(f_A-f_B)\]
If we make the change of strategy $A$ constant over time, which means $\frac{dx}{dt}=0$ then we can write the replicator dynamics equation as:
\[x_A(1-x_A)(f_A-f_B)=0\]
Now, if we try to find certain conditions under which $\frac{dx}{dt}$ will be $0$.
We will have three certain conditions, $x=0$, $x=1$, and $f_A=f_B$.
In graphical representation, for the condition $f_A=f_B$, it will make a straight line between $0$ and $1$. If the condition is $f_A>f_B$ then the curve will be over the straight line and if $f_A<f_B$ then the curve will be under the straight line\citep{Bishop1976}.\\
We can calculate the particular frequency where the strategy $A$ becomes abundant from rare or rare from abundant. We can calculate this using the $f_A=f_B$ equation.\\
Let's take this frequency as $x^*$.
As we know, $f_A=f_B$
So we can write,
\begin{align}
&xa_1+(1-x)a_0 =xb_1+(1-x)b_0 \nonumber\\
&x(a_1-a_0)+a_0=x(b_1-b_0)+b_0 \nonumber\\
&x(a_1-a_0-b_1+b_0)=b_0-a_0 \nonumber\\
&x=\frac{b_0-a_0}{a_1-a_0-b_1+b_0} \nonumber
\end{align}
We can write the $x$ as $x^*$
\begin{align}
x^*=\frac{b_0-a_0}{a_1-a_0-b_1+b_0} \label{eq:5}
\end{align}
We get different conditions from this equation.\\
(1) Dominance: It happens when one of the two strategies will be dominant over another, meaning, for example, if $f_A>f_B$, that strategy $A$ will be dominant over strategy $B$. It will be possible if the $a_1>b_1$ and $a_0>b_0$, where $a_1,a_0,b_1,b_0$ are the payoffs of a payoff matrix of a two-player two-strategy game.\\
(2) Co-existence: It happens when one of the two strategies is rare and has an advantage over that. For example, if strategy $A$ is rare, then $f_A>f_B$. If $a$ becomes abundant, it will lose its advantage, so the inequality will be  $f_A<f_B$, and while becoming abundant strategy from rare strategy, there will be an internal equilibrium point, and the equation will be $f_A=f_B$. In this scenario, the player should play the rare strategy. It will be possible if the $a_1<b_1$ and $a_0>b_0$, where $a_1,a_0,b_1,b_0$ are the payoffs of a payoff matrix of a two-player two-strategy game.\\
(3) Bi-stability: A condition where all $A$ and $B$ will be stable. It means that a strategy will get an advantage if it is abundant. For example, if strategy $A$ is abundant, then the inequality will be $f_A>f_B$, and if it becomes rare, then the inequality will be $f_A<f_B$, and there will be an internal equilibria when $f_A=f_B$. For this condition, the player should play the strategy that its opponent is playing. It will be possible if the $a_1>b_1$ and $a_0<b_0$, where $a_1,a_0,b_1,b_0$ are the payoffs of a payoff matrix of a two-player two-strategy game.\\
(4) Neutrality: Now, we have one condition in which both strategies will have the same impact. It does not depend on the change in the strategy. The equation for this strategy is $f_A=f_B$. It will be possible if $a_1=b_1$ and $a_0=b_0$ where $a_1,a_0,b_1,b_0$ are the payoffs of a payoff matrix of a two-player two-strategy  game.\citep{Gokhale2011}.\\
Now, based on the above explained process of replicator dynamics for two players with two strategies, we will explore some games and find their internal equilibrium point.\\
\textbf{Prisoner's dilemma}
\newline
The prisoner's dilemma is a fundamental game in game theory, which represents that two rational individuals might not cooperate, even if it benefits them mutually.\\
The game goes on as two prisoners ($A$ player and $B$ player) are arrested by a policeman and offered some separate deals.\\
There will be mainly three conditions:
\begin{enumerate}
\item If both prisoners cooperate, they will get an equal and moderate amount of sentence.
\item If one prisoner defects, the defector will get no sentence, but the cooperator gets a longer sentence.
\item If both players defect, both will get a lower and equal sentence.
\end{enumerate}
Let's try to write the payoff matrix.
\[
\begin{array}{c|cc}
   & \text{Cooperate (C)} & \text{Defect (D)} \\
  \hline
  \text{Cooperate (C)} & R = 3 & S = 0 \\
  \text{Defect (D)} & T = 5 & P = 1 \\
\end{array}
\]
The general and standard condition for the prisoner' dilemma is $a_1<b_1$ and $a_0<b_0$. As mentioned in the replicator dynamics section, there are three conditions where the value of $dx/dt$ will be $0$. The three conditions are $x=0$, which means only defectors, and $x=1$, which means only cooperators. The internal equilibrium will fulfil the condition of $f_C=f_D$. Let's find the equilibrium point by using the equation \eqref{eq:5} and putting the payoff values into the equation.
\begin{align}
x^*&=\frac{1-0}{3-0-5 +1} \nonumber\\
x^*&= -1 \nonumber
\end{align}
Since $x\in{0,1}$ so there can not exist any internal equilibrium valued $-1$. This states that the entire system will transition to full defection $(x=0)$ over time.
We can plot the graph using Python for the Prisoner's dilemma dynamics.
\begin{figure}[H]
    \centering
    \includegraphics[width=0.6\textwidth]{PD.pdf}
    \caption{$x^*=-1$, Internal Equilibrium for Prisoner's Dilemma Game}
    \label{fig:1}
\end{figure}
\textbf{Chicken Game}
\newline
In this game, two players( player $A$ and player $B$)are driving towards each other on a single pathway. There are two options for the players:
\begin{enumerate}
\item Swerve(C)- Avoided collision but appeared weak.
\item Stay (D)- Stay driving toward each other, hoping the opponent will swerve.
\end{enumerate}
We can write three conditions based on this:
\begin{enumerate}
\item If both swerve, they will not face a collision, but there will be a small loss.
\item If one swerves and one stays, the one who stays will have a win, and the one who swerves will face a loss.
\item If both stay, they'll have a huge loss.
\end{enumerate}
We can write the payoff matrix with actual payoffs, which follow the standard condition, $a_1<b_1$ and $a_0>b_0$.
\[
\begin{array}{c|cc}
   & \text{Swerve} & \text{Stay} \\
  \hline
  \text{Swerve} & -c = -3 & b = 4 \\
  \text{Stay} & 0 = 0 & \frac{b}{2} = 2 \\
\end{array}
\]
As we know, there are three conditions where the value of $\frac{dx}{dt}$ will be $0$. The three conditions are $x=0$, which means only defectors, and $x=1$, which means only cooperators. The internal equilibrium will fulfil the condition of $f_C=f_D$.Let's find the equilibrium point by using the equation \eqref{eq:5} and putting the payoff values into the equation.
\begin{align}
x^*&= \frac{2-4}{-3-4-0+2} \nonumber\\
x^*&= \frac{2}{5} \nonumber
\end{align}
This implies that, over time, $2/5$ of the population will swerve and $3/5$ of the population will stay. It implies the condition of co-existence. Let's try to plot it.
\begin{figure}[H]
    \centering
    \includegraphics[width=0.6\textwidth]{CG.pdf}
    \caption{$x^*=\frac{2}{5}$, Internal Equilibrium for Chicken Game}
    \label{fig:2}
\end{figure}
\textbf{Stag Hunt Game}
\newline
The stag hunt game is a classical example of game theory for understanding social dilemma and the interplay between risk and trust.
In this game, two players are hunting in a forest. They have two choices: Cooperate(C) with each other and hunt a stag or Independently hunt hare(D).\\
We can write three conditions based on this:
\begin{enumerate}
\item If they both cooperate and hunt stag, they will get the highest payoff.
\item If One goes for the stag hunt and the other one hunts hare, the one who hunts stag will get nothing and the one who hunts hare will get a lower payoff.
\item If they both defect and independently hunt hare, they will get a lower payoff.
\end{enumerate}
We can write the payoff matrix using actual values, which follow the conditions of $a_1>b_1$ and $a_0<b_0$.
\[
\begin{array}{c|cc}
   & \text{Cooperate (C)} & \text{Defect (D)} \\
  \hline
  \text{Cooperate (C)} & S = 4 & S = 1 \\
  \text{Defect (D)} & H = 3 & H = 3 \\
\end{array}
\]
As we know, there are three conditions where the value of $dx/dt$ will be $0$. These three conditions are $x=0$, it means only defectors, and $x=1$, which means only cooperators. The internal equilibrium will fulfil the condition of $f_C=f_D$.Let's find the equilibrium point by using the equation \eqref{eq:5} and putting the payoff values into the equation.\\
\begin{align}
x^* &=\frac{3-1}{4-1-3+3} \nonumber\\
x^* &= \frac{2}{3} \nonumber
\end{align}
Over time, $2/3$ of the population will hunt hare and the $1/3$ of the population will hunt stag.
\begin{figure}[H]
    \centering
    \includegraphics[width=0.6\textwidth]{SH.pdf}
    \caption{$x^*=\frac{2}{3}$, Internal Equilibrium for Stag Hunt Game}
    \label{fig:3}
\end{figure}
\subsubsection{Two player games with multiple strategies}
In the previous subsection, we analysed two player games with two strategies, now we are going to analyse two player games with multiple strategies. For better understanding of this particular problem, let's take a biological example, strains of \textit{Escherichia coli} are competing for resources available on the media. $K$ strain is the killer strain which produces toxin that will out-compete strain $S$. So, having toxin or not are the two strategies, we can write this using two strategy payoff matrix but there can be another possibility, where strain $R$ is resistant to the toxin but pay the cost for resistance. So, the scenario now changed completely; now the payoff matrix will be $3 \times 3$. This study was carried out by\citep{Kerr2002}\citep{Czaran2002}.
Now, in a population there will be multiple strategies. So, we have to write the replicator dynamics in $(n-1)$ dimensional simplex.For that we need $n\times n$ payoff matrix.
\[
\begin{array}{c@{}c}
   & \begin{array}{cccc} 1 & 2 & \dots & n \end{array} \\ 
   \begin{array}{c} 
       1 \\ 
       2 \\ 
       \vdots \\ 
       n 
   \end{array} 
   & 
   \begin{pmatrix}
       a_{1,1} & a_{1,2} & \dots & a_{1,n} \\
       a_{2,1} & a_{2,2} & \dots & a_{2,n} \\
       \vdots & \vdots & \ddots & \vdots \\
       a_{n,1} & a_{n,2} & \dots & a_{n,n}
   \end{pmatrix}
\end{array}
\] \label{eq:6}
This is a two player game, here $a_{1,2}$ means player $A$ playing strategy $1$ against the strategy $2$ of player $B$ so we can write the equation using replicator dyanmics.
\begin{equation}
dx_i/dt=x_i[f_i(x)-\bar{f}\nonumber\\
\end{equation}
We can derive the average fitness of a strategy $i$ from this equation.
\begin{equation}
f_i(x)=a_{i,1}x_1+a_{i,2}x_2+.....+a_{i,n}x_n\nonumber\\
\end{equation}
We can write this equation as:
\begin{equation}
f_i(x)=\sum_{j=1}^{n}a_{i,j}x_j\nonumber\\
\end{equation}
and the average fitness of a population is denoted as:
\begin{equation}
\bar{f}=x_1f_1+x_2f_2+.....+x_nf_n= \sum_{i=1}^{n}x_if_i\nonumber\\
\end{equation}
\textbf{Rock-Paper-Scissors Game}
\newline
Rock paper scissors game is a game in game theory where, there are $n=3$ strategies for each player. In this game, there are mainly three conditions:
\begin{enumerate}
\item If rock, paper and scissors meet respectively with rock, paper and scissors, the payoff will be zero.
\item If rock meets with scissors and paper with rock and scissors with paper, they will get the highest payoff.
\item If the rock meets with paper and paper with scissors and scissors with rock, they will get the lowest payoff.
\end{enumerate}
Let's try to write the payoff matrix.
\begin{equation}
A =
\begin{pmatrix}
  & R & S & P \\
R & 0 & 1 & -1 \\
S & -1 & 0 & 1 \\
P & 1 & -1 & 0
\end{pmatrix}
\end{equation}
Let's write the average fitness for each strategy,\\
For Rock,
\begin{align}
f_R &= (0)x_R + (1)x_S + (-1)x_P \nonumber\\
f_R &= x_S - x_P \nonumber
\end{align}
For Scissors,
\begin{align}
f_S &= (-1)x_R + (0)x_S + (1)x_P \nonumber\\
f_S &= x_P - x_R \nonumber
\end{align}
For Paper,
\begin{align}
f_P &= (1)x_R + (-1)x_S + (0)x_P \nonumber\\
f_P &= x_R - x_S \nonumber
\end{align}
$x_R,x_S,x_P$ are the frequencies of choosing rock, scissors and paper respectively, and we can write,
\begin{align}
x_R+x_S+x_P=1 \label{eq:7}
\end{align}
Now the mathematical condition for finding the internal equilibrium is $f_R=f_S=f_P$.
\begin{align}
f_R &=f_S \nonumber\\
x_S-x_P &=x_P-x_R \nonumber\\
2x_P &=x_S+x_R \label{eq:8}
\end{align}
\begin{align}
f_S &=f_P \nonumber\\
x_P-x_R &=x_R-x_S \nonumber\\
2x_R &=x_P+x_S \label{eq:9}
\end{align}
\begin{align}
f_R&=f_P \nonumber\\
x_S-x_P&=x_R-x_S \nonumber\\
2x_S&=x_R+x_P \label{eq:10}
\end{align}
Now if we replace the value of \eqref{eq:7} into the equation \eqref{eq:6} we will get,
\begin{align}
x_R+x_S+x_P&=1\nonumber\\
2x_P+x_P&=1\nonumber\\
x_P&=\frac{1}{3}\nonumber
\end{align}
If we replace the value of \eqref{eq:8} and \eqref{eq:9} into the equation \eqref{eq:6} in the same manner, we will get $x_P=x_R=x_S=\frac{1}{3}$. In this game no player will gain an advantage by changing their strategies.
\begin{figure}[H]
    \centering
    \includegraphics[width=0.6\textwidth]{RPS.pdf}
    \caption{Internal Equilibrium of Rock-Paper-Scissors Game}
    \label{fig:4}
\end{figure} 
\subsection{Stochastic Process and Finite Population}
\subsubsection{Two players with two strategies}
In the previous subsection, we used an infinite population for the deterministic approach \citep{Hofbauer2003}.
Now, we will proceed with a finite population.
There are mainly two reasons to use a finite population: first, it is realistic, and second, it is a natural way to introduce randomness into the replicator dynamics \citep{Altrock2010}.\\
\textbf{Wright-Fisher Process}
\newline
The theory of Wright-Fisher process is rooted in the population genetics. In Wright-Fisher process,each of $N$ individuals in a generation reproduce a large number of offspring which is proportional to their fitness.
From this offspring pool, a $N$ sized generation is again randomly sampled. The composition of the population can change more faster. In principle, in a single generation, the population can go back to a single ancestor. 
It states that the Wright-Fisher process is not a simple birth-death process. It is a more general Markov chain process \citep{Imhof2006}.\\
\textbf{Moran Process}
\newline
Moran process is a classical model of population genetics like Wright-Fisher process. In contrast to the Wright-Fisher process, Moran process is a simple birth-death process, where in a population one randomly selected individual reproduce it's identical copy proportional to it's fitness value and to keep the population size constant one randomly selected individual is removed from the population.
In the previous works, we used trivial fitness means the average fitness is exactly equal to the average payoff. But in the actual population, fitness can depend on payoff in many other ways. For some systems we may know the exact relation between payoff and fitness but for other systems, we can just speculate.
Nowak et al.\citep{Nowak2004} introduced a tunable parameter as selection intensity. 
\begin{equation}
f_i=1-w+w\pi_i \label{eq:11}
\end{equation}
where $f_i$ is the average fitness of a population, $w$ is the selection intensity, $\pi_i$ is the average payoff of a strategy. If $w=1$ it will be strong selection, $f_i=\pi_i$ and if $w=0$ it will be weak selection, $f_i=1$.\\
Now, we can consider the finite population of a specific game as $N$.
Let's assume there are two strategies $A$ and $B$. Number of players playing strategy $A$ and $B$ are $j$ and $(N-j)$ respectively.
We can write the payoff matrix according to this specification.
\[
\begin{array}{c|cc}
    & A & B \\
    \hline
  A & a_1 & a_0 \\
  B & b_1 & b_0
\end{array}
\]
Now we can denote the average payoff of $a$ and $b$ strategies as $\pi_a$ and $\pi_b$.
\begin{align}
\pi_A&=\frac{j-1}{N-1}a_1 + \frac{N-j}{N-1}a_0 \nonumber\\
\pi_B&=\frac {j}{N-1}b_1 + \frac{N-j-1}{N-1}b_0\label{eq:12}
\end{align}
Now, a question can arise, why are we using $j-1$ instead of $j$? We have to understand that instead of an infinitely large population, we are using a real finite population and for that, we have to remove the particular individual who is observing or analysing the situation, so we use $j-1$.\\
Now, we can move to the part of the evolutionary dynamics for the finite population where randomness is involved in the population.
So, we will go for the stochastic processes.
For these stochastic processes, we will focus on the Moran process. It consists of two events: birth and death. 
For the birth process, one subject is chosen randomly, and it produces its identical copy, and for the death process, again, one random subject is chosen from the population and eliminated. 
It means by introducing randomness with the birth-death process, now this theory can change the population with each time step, and for $N$ steps it will control a generation \cite{Moran1962}
There are three situations in this theory.
\begin{enumerate}
\item The number of individual playing strategy $A$ increases by 1.
\item The number of individual playing strategy $A$ decreases by 1.
\item The number of individual playing strategy $A$ remains neutral.
\end{enumerate}
From these three scenarios we can write there equations.\\
For the (1) scenario,
\begin{equation}
T_j^+=\frac{jf_A}{jf_A+(N-j)f_B}\frac{N-j}{N} \label{eq:13}
\end{equation}
For the (2) scenario,
\begin{equation}
T_j^-=\frac{(N-j)f_A}{jf_A+(N-j)f_B}\frac{j}{N} \label{eq:14}
\end{equation}
For the (3) scenario,
\begin{equation}
1-T_j^+-T_j^- \label{eq:15}
\end{equation}
Now, what can we tell from these equations?
\begin{enumerate}
\item From the \eqref{eq:12} equation, we can say that  individual playing strategy $A$ can increase only when an individual playing strategy $A$  is chosen for birth and an individual playing strategy $B$  is chosen for death.
\item From the \eqref{eq:13} equation, we can say that the number of the individuals playing strategy $A$ decreases because an individual playing strategy $A$ individual is chosen for death and an individual playing strategy $B$ is chosen for birth.
\item From the \eqref{eq:14} equation, we can deduce that no one is chosen for the birth or death process, so there is neutrality.
\end{enumerate}
\textbf{Fixation Probability}
\newline
In genetics, we often ask a question related to the invasion of a gene: how can the gene invade another gene, and how does it affect the other gene's population?
After understanding the transition probability and Moran processes, we can now form a question based on the previously mentioned topic.
In a population of $j$ numbered individuals playing strategy $A$ and $(N-j)$ numbered individuals playing strategy $B$, what is the probability of the whole population will consist of individuals playing $A$?
This is known as the fixation probability of $j$ numbered individuals playing $A$ strategy.
We can denote this fixation probability as $\rho_j$.
The two absorbing states are $\rho_j=0$ and $\rho_j=1$.
Since fixation is an absorbing state, if the entire population once becomes $A$, it can not be reverted. We can try to write a probability balance equation.
\begin{align}
\rho_j &= T_j^-\rho_{j-1}+(1-T_j^+ - T_j^-)\rho_j + T_j^+p_{j+1} \nonumber\\
0 &= T_j^-\rho_{j-1} - T_j^-\rho_j - T_j^+\rho_j + T_J^+\rho_{j+1}\nonumber\\
0 &= \underbrace{-T^-_j (\rho_j - \rho_{j-1})}_{y_j} + \underbrace{T^+_j (\rho_{j+1} - \rho_j)}_{y_{j+1}} \label{eq:16}
\end{align}
We can write this equation as the differences between fixation probabilities, $y_{j+1}=y_jr_j$, where $r_j=\frac{T_j^-}{T_j^+}$
\begin{align}
y_1 &= \rho_1 - \rho_0 = \rho_1 \nonumber\\
y_2 &= \rho_2 - \rho_1 = r_1 \rho_1 \nonumber\\
\vdots \nonumber\\
y_k &= \rho_k - \rho_{k-1} = \rho_1 \prod_{j=1}^{k-1} r_j \label{eq:17}\\
\vdots \nonumber\\
y_N &= \rho_N - \rho_{N-1} = \rho_1 \prod_{j=1}^{N-1} r_j \label{eq:18}
\end{align}
This means each incremental change from $\rho_{N-1}$ to $\rho_N$ is based on the growing product of $r_j$ multiplied by $\rho_1$.\\
Now let's calculate the sum over all $y_j$. This sum is telescopic sum.
\begin{align}
\sum_{k=1}^N y_k &= \rho_1-\rho_0+ \rho_2-\rho_1+ \rho_3-\rho_2+\cdots+\rho_N-\rho_{N-1} \nonumber\\
\sum_{k=1}^N y_k &= \rho_N-\rho_0=1 \label{eq:19}
\end{align}
Using \eqref{eq:16} and \eqref{eq:18} we can calculate the value of $\rho_1$.
\begin{equation}
1=\sum_{k=1}^N y_k=\sum_{k=1}^N \rho_1 \prod_{j=1}^{N-1}r_j=\rho_1(1+ \sum_{k=1}^{N-1}\prod_{j=1}^k r_j)\label{eq:20}
\end{equation}
So, we can write the fixation probability of one $A$ individual as,
\begin{equation}
\rho_1= \frac{1}{1+ \sum_{k=1}^{N-1}\prod_{j=1}^k r_j} \label{eq:21}
\end{equation}
For neutral selection, $T_j^-=T_j^+$ and $r_j=1$. Hence, all products are simply one and we find $\rho_1= 1/N$.\\
This is the fixation probability of single mutant $\rho_1$. In general, the fixation probability of $i$ mutants are $\rho_i$.
\begin{align}
\rho_i&= \sum_{k=1}^i y_k \nonumber\\
&= \rho_1 \sum_{k=1}^i \prod_{j=1}^{k-1}r_j\nonumber\\
&=\rho_1(1+ \sum_{k=1}^{i-1} \prod_{j=1}^k r_j)\nonumber\\
&= \frac{1+\sum_{k=1}^{i-1}\prod_{j=1}^k r_j}{1+ \sum_{k=1}^{N-1}\prod_{j=1}^k r_j} \label{eq:22}
\end{align}
For neutral selection, we have $T_j^-=T_j^+$ and $r_j=1$. Hence, all products are simply one and we find $\rho_1= j/N$.\\
The probability that a single individual playing strategy $A$ takes over a population of $N-1$ individuals playing strategy $B$ is the fixation probability of strategy $A$, $\rho_A=\rho_1$.\\
The probability that a single individual playing strategy $B$ takes over a population of $N-1$ individuals playing strategy $A$ is the fixation probability of strategy $B$. The fixation probability of $B$ strategy is equal to the $N-1$ individuals playing strategy $A$ fail to take over the population so there is only one individual playing strategy $B$. So, the fixation probability of strategy $B$ is $\rho_B= 1-\rho_{N-1}$.\citep{traulsen2009stochastic}
\begin{align}
\rho_B &=1-\rho_{N-1} \nonumber\\
&=\frac{1 + \sum_{k=1}^{N-2} \prod_{j=1}^{k} r_j}{1 + \sum_{k=1}^{N-1} \prod_{j=1}^{k} r_j} \nonumber\\
&= \frac{1 + \sum_{k=1}^{N-1} \prod_{j=1}^{k} r_j}{1 + \sum_{k=1}^{N-1} \prod_{j=1}^{k} r_j} - \frac{1 + \sum_{k=1}^{N-2} \prod_{j=1}^{k} r_j}{1 + \sum_{k=1}^{N-1} \prod_{j=1}^{k} r_j} \nonumber\\
&= \frac{\prod_{j=1}^{N-1} r_j}{1 + \sum_{k=1}^{N-1} \prod_{j=1}^{k} r_j} \nonumber \\
&= \rho_A \prod_{j=1}^{N-1} r_j \label{eq:23}
\end{align}
\textbf{Weak Selection and Risk Dominance}
\newline
For weak selection, selection intensity is $w\ll 1$ and $r_j$ simplifies to,
\begin{equation}
r_j = \frac{1-w+w\pi_B}{1-w+w\pi_A} \approx 1-w(\pi_A-\pi_B) \label{eq:24}
\end{equation}
Now we can write the product in the \eqref{eq:21} in a simplified way for weak selection.
\begin{equation}
\prod_{j=1}^k r_j \approx \prod_{j=1}^k 1-w(\pi_A-\pi_B) \approx 1-w \sum_{j=1}^k (\pi_A-\pi_B). \label{eq:25}
\end{equation}
Now, let's annotate a equation $(\pi_A-\pi_B)$.
From equation \eqref{eq:12} we can write,
\begin{align}
\pi_A - \pi_B &= \frac{(j - 1)a + (N - j)b - jc - (N - j - 1)d}{N - 1} \nonumber\\
&= \frac{j(a - b - c + d) + (-a + bN - dN + d)}{N - 1}\nonumber\\
&= \underbrace{\frac{a - b - c + d}{N - 1}}_{u} j 
+ \underbrace{\frac{-a + bN - dN + d}{N - 1}}_{v} \label{eq:26}
\end{align}
Now, let's solve the sum for the payoff difference using equation \eqref{eq:26}.
\begin{equation}
\sum_{j=1}^{k} (\pi_A - \pi_B) = \sum_{j=1}^{k} (u j + v) = u \frac{(k+1)k}{2} + vk = \frac{u}{2}k^2 +( \frac{u}{2} + v)k. \label{eq:27}
\end{equation}
Now, the ratio of fixation probabilities:
\begin{align}
\frac{\rho_B}{\rho_A} &= \prod_{j=1}^{N-1}r_j \approx 1 - w \sum_{j=1}^{N-1} (\pi_A - \pi_B)\nonumber\\
&= 1 - w[ \frac{u}{2}(N-1) + \frac{u}{2} + v](N-1) \nonumber\\
&= 1 - \frac{w}{2} \underbrace{[(a - b - c + d)(N - 1) - a - b - c + 3d + (2b - 2d)N]}_{\Xi} \label{eq:28}
\end{align}
If the payoff difference is $\Xi > 0$, then only strategy $A$ will be favoured, means $\rho_A>\rho_B$.
For large population, $N \gg 1$ we can write that
\begin{equation}
0<\Xi \approx N(a+b-c-d)\label{eq:29}
\end{equation}
It is equivalent to
\begin{equation}
x^*=\frac{d-b}{a-b-c+d}<\frac{1}{2} \label{eq:30}
\end{equation}
So, we can write that $\rho_A >\rho_B$ is equivalent to $x^*<\frac{1}{2}$.
This condition is risk dominance and it implies that for weak selection, strategies which have higher fixation probabilities can invade and fixate from a wider range of starting conditions.\\
\textbf{One-Third Rule}
\newline
Now we can write the approximation of the fixation probability equation under weak selection by inserting equation \eqref{eq:27} into equation \eqref{eq:21}.
\begin{align}
\rho_1 &= \frac{1}{1+\sum_{k=1}^{N-1} \prod_{j=1}^{k}r_j}\nonumber\\
&\approx \frac{1}{1+\sum_{k=1}^{N-1}[1-w(\frac{u}{2}k^2+(\frac{u}{2}+v)k)]} \label{eq:31}
\end{align}
If we use the formula $\sum_{k=1}^{N-1} k = \frac{N(N - 1)}{2}$ and $\sum_{k=1}^{N-1} k^2 = \frac{N(N - 1)(2N - 1)}{6}$, the fixation probability will be,
\begin{align}
\rho_1 &\approx\frac{1}{(N - 1)- w [\frac{u}{2}\frac{N(N - 1)(2N - 1)}{6} + (\frac{u}{2} + v)\frac{N(N - 1)}{2}]}\nonumber\\
&\approx \frac{1}{N - w[ u \frac{N(N - 1)(2N - 1)}{12} + ( \frac{u}{2} + v)\frac{N(N - 1)}{2}]}\nonumber\\
&\approx \frac{1}{N - wu \cdot \frac{N(N - 1)(2N - 1)}{12} - w ( \frac{u}{2} + v)\frac{N(N - 1)}{2}} \nonumber\\
&= \frac{1}{N} + \frac{w}{4N}[\underbrace{( a - b - c + d)\frac{2N - 1}{3} - a - b - c + 3d + (2b - 2d)N
}_{\Gamma}] \label{eq:32}
\end{align}
Now take this condition for $w=0$ which is known as neutral selection.
Neutral selection means there is no selective force working, and the fixation is totally determined by randomness.
So, in the case of neutral selection the fixation probability $\rho_1 = \frac{1}{N}$.
Now, if we want to know that if the fixation probability is higher than $\frac{1}{N}$ or not, we need to consider $\Gamma$.
If $\Gamma>0$ then only fixation probability will be greater than $\frac{1}{N}$.
\begin{equation}
\frac{a-b-c+d}{3}+ b-d > 0 \label{eq:33}
\end{equation}
The condition showed in the \eqref{eq:33} is equivalent to,
\begin{equation}
x^* = \frac{d-b}{a-b-c+d}<\frac{1}{3} \label{eq:34}
\end{equation}
This condition is known as one-third rule.
It implies that the fixation probability of a strategy will be higher than $\frac{1}{N}$, meaning the strategy is more likely to fix than by random drift, if and only if the unstable tipping point $x^*$ is less than $\frac{1}{3}$ \citep{Ohtsuki2007}.
\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{SH_FP_SIM.pdf}
    \caption{Fixation probability in the Stag Hunt game for a population size $N = 30$, based on $10^4$ simulations. The results correspond to the analytical expression given in equation~\eqref{eq:22}. The $X$-axis represents $i/N$, where $i=$ initial mutant number and $N$ is the population number. The $Y$-axis represents fixation probability.}
    \label{fig:5}
\end{figure}



\subsubsection{Two Players with multiple strategies}
In the previous section we've discussed about the Moran process and fixation probability for  two player two strategy games,
but in this section the aim is to explain the same for the two player multiple strategy games.\\
Let's take the example of Rock-Paper-Scissors game for explaining the Moran process for multiple strategy games.
Suppose,it is a well mixed finite population of fixed size $N$.
Individuals can adopt one of three strategies: Rock(R), Paper(P), Scissors(S).
Number of individuals playing these strategies are $i_R$, $i_P$, $i_S$.
In a $N$ sized finite population, the number of players using each and every strategy should be an integer between $0$ and $N$, and their sum must be exactly $N$. So it can be written that,
\begin{equation}
i_R+i_P+i_S = N \label{eq:35}
\end{equation}
Now, let's write the payoff matrix for the RPS game.
\begin{equation}
A =
\begin{pmatrix}
  & R & S & P \\
R & 0 & 1 & -1 \\
S & -1 & 0 & 1 \\
P & 1 & -1 & 0
\end{pmatrix} \label{eq:36}
\end{equation}
Now let's write the average payoff value for each strategy.
\begin{equation}
\pi_R= i_S - i_P \label{eq:37}
\end{equation}
\begin{equation}
\pi_S= i_P - i_R \label{eq:38}
\end{equation}
\begin{equation}
\pi_P= i_R - i_S \label{eq:39}
\end{equation}
Now the individuals are selected proportional to fitness at birth and proportional to inverse  fitness at death at selection intensity $w$.
Then, the linear fitness for a strategy is $f=1-w+w\pi$.
There are six transition probabilities in each state.
The transition probabilities in each state and to change into one of the six neighbouring states are given by a general equation.
\begin{equation}
T_{Y \to X}(i_R,i_S,i_P)= \frac{i_X f_X}{\sum_Z i_Z f_Z} \cdot \frac{i_Y}{N} \label{eq:40}
\end{equation}
where $X,Y,Z \in (i_R,i_P,i_S)$.\\
Now let's try to write these six transition probabilities,
where each step of the Moran process consists of:
\begin{enumerate}
\item Selection of an individual for reproduction, proportional to fitness.
\item Selection of an individual for death, uniformly at random.
\end{enumerate}
We can write the fitnesses as \( f_R, f_P, f_S \) where,
\begin{align}
f_R &= 1-w+w\pi_R \nonumber\\
f_S &= 1-w+w\pi_S \nonumber\\
f_P &= 1-w+w\pi_P \label{eq:41}
\end{align}
and the total fitness of the population be:
\begin{equation}
\phi = i_R f_R + i_P f_P + i_S f_S \label{eq:42}
\end{equation}
Then, the six transition probabilities are 
\begin{enumerate}
\item Rock reproduces, Paper dies: $T_{P \to R}$.
\begin{align}
T^{R+} &= \frac{i_R f_R}{\phi} \cdot \frac{i_P}{N} \label{eq:43}
\end{align}
\item Paper reproduces, Rock dies: $T_{R \to P}$.
\begin{align}
T^{R-} &= \frac{i_P f_P}{\phi} \cdot \frac{i_R}{N}\label{eq:44}
\end{align}
\item Paper reproduces, Scissors dies: $T_{S \to P}$.
\begin{align}
T^{P+} &= \frac{i_P f_P}{\phi} \cdot \frac{i_S}{N} \label{eq:45}
\end{align}
\item Scissors reproduces, Paper dies: $T_{P \to S}$.
\begin{align}
T^{P-} &= \frac{i_S f_S}{\phi} \cdot \frac{i_P}{N} \label{eq:46}
\end{align}
\item Scissors reproduces, Rock dies: $T_{R \to S}$.
\begin{align}
T^{S+} &= \frac{i_S f_S}{\phi} \cdot \frac{i_R}{N} \label{eq:47}
\end{align}
\item Rock reproduces, Scissors dies: $T_{S \to R}$.
\begin{align}
T^{S-} &= \frac{i_R f_R}{\phi} \cdot \frac{i_S}{N} \label{eq:48}
\end{align}
\item everyone stays at the same state:
\begin{align}
T_{\text{Stay}}(i_R,i_P,i_S) = T_{R \to R} + T_{S \to S} + T_{P \to P} \label{eq:49}
\end{align}
\end{enumerate}
All six of these transition probabilities completely determine the stochastic dynamics of the Moran process of a three-strategy game such as Rock-Paper-Scissors.
The population will move to any one of the six neighbouring states at each time step in the strategy simplex, which means it will move to a state where one strategy will be increased and another decreased by $1$ person.
The development of this system is a Markov chain process over the state space of all feasible $(i_R, i_P, i_S)$ triplets fulfilling equation \eqref{eq:35}.
This process continues until it arrives at one of the absorbing boundaries, which means only one strategy remains and all other strategies become extinct.
These absorbing states can be equated to fixation of single strategy.
\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{RPS_FP.pdf}
    \caption{In a finite population of size $N = 33$, with $10^4$ simulations and a zero-sum payoff matrix \eqref{eq:36}, the fixation probability of Rock is highest near the Rock-rich corner. This is because, under strong selection ($w = 1$), strategies with higher initial frequencies have greater chances to fixate. Since Rock starts in high abundance in this region, it dominates via replication advantage over time.}
    \label{fig:6}
\end{figure}



\section{Results}
\section{Discussion}


\textbf{Code availability}.
Appropriate computer code describing the model is available at 
\texttt{ REDACTED for review}.% {\url{https://github.com/tecoevo/beliefs}}.

\section{Acknowledgements}
\texttt{ REDACTED for review}.% {\url{https://github.com/tecoevo/beliefs}}.


\bibliographystyle{naturemag}
\bibliography{references.bib}

\renewcommand{\theequation}{SI.\arabic{equation}}
\setcounter{equation}{0}

\renewcommand{\thefigure}{SI.\arabic{figure}}
\setcounter{figure}{0}

\section{Supplementary material}


\subsection{Analysis of the simple system}




\end{document}
